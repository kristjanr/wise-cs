{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-14T15:18:31.835208Z",
     "end_time": "2023-05-14T15:18:31.839218Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_text(text):\n",
    "    # Replace newline characters with spaces\n",
    "    cleaned_text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    # Replace multiple spaces with a single space\n",
    "    cleaned_text = \" \".join(cleaned_text.split())\n",
    "    return cleaned_text\n",
    "\n",
    "def parse_section(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    buttons = soup.find_all('button')\n",
    "    accordion_contents = soup.find_all('div', {'data-testid': lambda x: x and x.startswith('accordion-content-')})\n",
    "    parsed_data = []\n",
    "    for i, (button, content) in enumerate(zip(buttons, accordion_contents), 1):\n",
    "        heading = button.find('h2').text\n",
    "        articles = []\n",
    "        list_items = content.find_all('li')\n",
    "        for j, li in enumerate(list_items, start=1):\n",
    "            a = li.find('a')\n",
    "            title = a.text\n",
    "            link = a['href']\n",
    "            articles.append(dict(title=clean_text(title), link=link, order=j))\n",
    "        parsed_data.append(dict(order=i, heading=clean_text(heading), articles=articles))\n",
    "    return parsed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import os\n",
    "\n",
    "data = []\n",
    "\n",
    "for section_folder_name in ['01-sending-money', '02-managing-your-account', '03-holding-money', '04-wise-card', '05-receiving-money', '06-wise-business']:\n",
    "    source_path = 'scraped-data/sections/' + section_folder_name + '/source.py'\n",
    "    module_name = os.path.basename(source_path).split('.')[0]\n",
    "    spec = importlib.util.spec_from_file_location(module_name, source_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    path = '/'.join(source_path.split('/')[:3])\n",
    "    order_str = source_path.split('/')[2][:2]\n",
    "    data.append(dict(path=path, order=int(order_str), link=module.link, heading=module.heading, title=module.title, subsections=parse_section(module.html)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T15:18:32.080742Z",
     "end_time": "2023-05-14T15:18:32.152565Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "\"{'path': 'scraped-data/sections/01-sending-money', 'order': 1, 'link': 'https://wise.com/help/topics/5bVKT0uQdBrDp6T62keyfz/sending-money', 'heading': 'Sending money', 'title': 'Setting up, paying for, editing, and cancelling transfers.', 'subsections': [{'order': 1, 'heading': 'Sending money basics', 'articles': [{'title': 'How do I send money with Wise?', 'link': '/help/articles/2977959/how-do-i-send-money-with-wise', 'order': 1}, {'title': 'How long does a transfer take?', 'link': '/help/arti\""
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(data[0])[:500]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T15:18:32.544585Z",
     "end_time": "2023-05-14T15:18:32.548915Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "\"{'order': 1, 'heading': 'Sending money basics', 'articles': [{'title': 'How do I send money with Wise?', 'link': '/help/articles/2977959/how-do-i-send-money-with-wise', 'order': 1}, {'title': 'How long does a transfer take?', 'link': '/help/articles/2524078/how-long-does-a-transfer-take', 'order': 2}, {'title': 'Can I send exact amounts?', 'link': '/help/articles/2448314/can-i-send-exact-amounts', 'order': 3}, {'title': 'How do you notify me about a transfer?', 'link': '/help/articles/2553293/ho\""
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(data[0]['subsections'][0])[:500]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T15:18:32.955053Z",
     "end_time": "2023-05-14T15:18:32.960527Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "{'title': 'How do I send money with Wise?',\n 'link': '/help/articles/2977959/how-do-i-send-money-with-wise',\n 'order': 1}"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['subsections'][0]['articles'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T15:18:33.269749Z",
     "end_time": "2023-05-14T15:18:33.275911Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# sum the number of articles in each content\n",
    "sanity_check = {d['order']: sum([len(subsection['articles']) for subsection in d['subsections']]) for d in data}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T15:18:33.852886Z",
     "end_time": "2023-05-14T15:18:33.857828Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "289"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of articles in total\n",
    "sum(sanity_check.values())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T15:18:34.415244Z",
     "end_time": "2023-05-14T15:18:34.420264Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "import csv\n",
    "from io import StringIO\n",
    "import requests\n",
    "import html2text\n",
    "# Convert HTML content to Markdown\n",
    "converter = html2text.HTML2Text()\n",
    "# Don't want to deal with inline links\n",
    "converter.ignore_links = True\n",
    "# Ignore images\n",
    "converter.ignore_images = True\n",
    "# Ignore tables\n",
    "converter.ignore_tables = True\n",
    "converter.body_width = 0  # Disable line wrapping\n",
    "\n",
    "base_url = \"https://wise.com\"\n",
    "\n",
    "table_csv_getvalue = ''\n",
    "\n",
    "\n",
    "def get_article_content(url):\n",
    "    global table_csv_getvalue\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    html = soup.find(\"div\", {\"class\": \"article-content\"})\n",
    "    related_articles_section = soup.find(\"ul\", {\"class\": \"css-1mcz8c5\"})\n",
    "    related_articles = []\n",
    "\n",
    "    for li in related_articles_section.find_all(\"li\"):\n",
    "        a = li.find(\"a\")\n",
    "        related_articles.append({\n",
    "            \"title\": a.get_text().strip(),\n",
    "            \"link\": base_url+ a[\"href\"]\n",
    "        })\n",
    "\n",
    "    # Convert tables to CSV and replace them with markers\n",
    "    tables = html.find_all(\"table\")\n",
    "    csv_tables = []\n",
    "    if tables:\n",
    "        print(f'Found {len(tables)} tables in {url}')\n",
    "    for i, table in enumerate(tables):\n",
    "        table_csv = StringIO()\n",
    "        csv_writer = csv.writer(table_csv, lineterminator='\\n')\n",
    "\n",
    "        rows = table.find_all(\"tr\")\n",
    "        for row in rows:\n",
    "            cells = row.find_all([\"th\", \"td\"])\n",
    "            cell_list = [cell.get_text().strip() for cell in cells]\n",
    "            csv_writer.writerow(cell_list)\n",
    "        table_csv_getvalue = table_csv.getvalue().replace(\"\\n\", \"  \\n\")\n",
    "        csv_tables.append(table_csv_getvalue)\n",
    "        table.replace_with(f\"CSV_TABLE_MARKER_{i}\")  # Place a marker\n",
    "\n",
    "    # Convert HTML to markdown\n",
    "    markdown_content = converter.handle(str(html))\n",
    "\n",
    "    # Replace markers with CSV tables\n",
    "    for i, table_csv_str in enumerate(csv_tables):\n",
    "        markdown_content = markdown_content.replace(f\"CSV_TABLE_MARKER_{i}\", \"\\n--- CSV table begins ---\" + \"  \\n\" + table_csv_str + \"--- CSV table ends ---  \\n\")\n",
    "\n",
    "\n",
    "    return html, markdown_content.strip(), related_articles\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T15:50:22.641983Z",
     "end_time": "2023-05-14T15:50:22.645220Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "from slugify import slugify\n",
    "import json\n",
    "\n",
    "for section in data:\n",
    "    os.makedirs(section['path'] + '/subsections/', exist_ok=True)\n",
    "    for subsection in section['subsections']:\n",
    "        subsection_folder = section['path'] + '/subsections/' + str(subsection['order']).zfill(2) + '-' + slugify(subsection['heading'])\n",
    "        os.makedirs(subsection_folder, exist_ok=True)\n",
    "        subsection['folder_path'] = subsection_folder\n",
    "        os.makedirs(subsection_folder + '/articles', exist_ok=True)\n",
    "        for article in subsection['articles']:\n",
    "            article_folder_name = slugify(article['title'])\n",
    "            article_folder_path = subsection_folder + '/articles/' + str(article['order']).zfill(2) + '-' + article_folder_name\n",
    "            # add article_folder_path to article\n",
    "            article['folder_path'] = article_folder_path\n",
    "            if os.path.exists(article_folder_path):\n",
    "                continue\n",
    "            os.makedirs(article_folder_path, exist_ok=False)\n",
    "            article_url = base_url + article[\"link\"]\n",
    "            print(f'Fetching {article_url} and saving to {article_folder_path}')\n",
    "            html, md, related_articles = get_article_content(article_url)\n",
    "            md_with_headings = f\"# {subsection['heading']}  \\n## {article['title']}  \\n{md}\"\n",
    "            with open(article_folder_path + '/' + 'content.md', 'w') as f:\n",
    "                f.write(md_with_headings)\n",
    "            with open(article_folder_path + '/' + 'metadata.json', 'w') as f:\n",
    "                metadata = dict(title=article['title'], link=article_url, related_articles=related_articles)\n",
    "                json.dump(metadata, f, indent=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T16:17:43.116304Z",
     "end_time": "2023-05-14T16:17:43.130949Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "## serialize data\n",
    "import json\n",
    "with open('scraped-data/index.json', 'w') as f:\n",
    "    json.dump(data, f, indent=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-14T16:18:00.164129Z",
     "end_time": "2023-05-14T16:18:00.172797Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "notebooks",
   "language": "python",
   "display_name": "notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
